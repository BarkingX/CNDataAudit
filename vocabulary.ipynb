{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import csv\n",
    "import itertools\n",
    "import json\n",
    "import locale\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "locale.setlocale(locale.LC_COLLATE, 'chinese')\n",
    "\n",
    "matplotlib.rcParams['font.sans-serif'] = ['SimHei']\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "label_mapping = {\n",
    "    '省级行政区': 'PLAD',\n",
    "    **{k: 'theme' for k in ['数据主题', '领域', '主题分类', '数据领域', '主题', '行业领域']},\n",
    "    **{k: 'format' for k in ['格式', '文件格式', '数据格式', '文件类型']},\n",
    "    **{k: 'accessLevel' for k in ['开放条件', '开放状态', '开放类型', '开放属性', '开放模式']},\n",
    "    **{k: 'accrualPeriodicity' for k in ['更新周期', '更新频率']},\n",
    "    **{k: 'resourceType' for k in ['服务类型', '资源类型']},\n",
    "}\n",
    "\n",
    "def standardized(data):\n",
    "    return [\n",
    "        {\n",
    "            label_mapping.get(key, key): value\n",
    "            for key, value in record.items()\n",
    "        }\n",
    "        for record in data\n",
    "    ]\n",
    "\n",
    "with open(r'output/json/vocabulary.json', 'r', encoding='utf-8') as file:\n",
    "    vocabulary = json.load(file)\n",
    "\n",
    "vocabulary = standardized(vocabulary)\n",
    "df = pd.DataFrame(vocabulary).drop(columns=['accrualPeriodicity', 'resourceType'])"
   ],
   "id": "7d509845a925b15b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df.info()\n",
    "df"
   ],
   "id": "639c18298c05705f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_themes = sorted([theme for themes in df['theme'] for theme in themes])\n",
    "wordcloud = WordCloud(font_path='simhei.ttf', width=2400, height=1200,\n",
    "                      background_color='white', collocations=False).generate(' '.join(all_themes))\n",
    "\n",
    "plt.figure(figsize=(16, 8), dpi=160)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(r'output/wordcloud/vocabulary.png')\n",
    "plt.show()"
   ],
   "id": "80809af55aa71df4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "heatmap_df = df.explode('theme').groupby(['PLAD', 'theme']).size().unstack(fill_value=0)\n",
    "heatmap_df = heatmap_df.loc[:, heatmap_df.sum(axis=0).sort_values(ascending=False).index]"
   ],
   "id": "62fb322b40e6e204",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def plot_kmeans_clusters(data):\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "    clusters = kmeans.fit_predict(data)\n",
    "    data['cluster'] = clusters\n",
    "    \n",
    "    for cluster in sorted(data['cluster'].unique()):\n",
    "        cluster_data = data[data['cluster'] == cluster].drop(columns='cluster')\n",
    "        cluster_data = cluster_data.loc[:, (cluster_data != 0).any(axis=0)]\n",
    "    \n",
    "        sorted_columns = cluster_data.sum(axis=0).sort_values(ascending=False).index\n",
    "        cluster_data = cluster_data[sorted_columns]\n",
    "    \n",
    "        plt.figure(figsize=(15, 10))\n",
    "        sns.heatmap(cluster_data, cmap='YlGnBu', annot=True, fmt='d')\n",
    "        plt.xlabel('主题')\n",
    "        plt.ylabel('省级行政区')\n",
    "        plt.title(f'聚类 {cluster} 内的主题词热图')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.show()\n",
    "\n",
    "plot_kmeans_clusters(heatmap_df.copy())"
   ],
   "id": "b1dcb0d6d4d8f520",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "\n",
    "\n",
    "def plot_hierarchical_clusters(data, method='ward', metric='euclidean', num_clusters=4):\n",
    "    Z = linkage(data, method=method, metric=metric)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    dendrogram(Z, labels=data.index, leaf_rotation=90)\n",
    "    plt.xlabel('省级行政区')\n",
    "    plt.ylabel('距离')\n",
    "    plt.title('省级行政区层次聚类树状图')\n",
    "    plt.show()\n",
    "\n",
    "    data['cluster'] = fcluster(Z, t=num_clusters, criterion='maxclust')\n",
    "    for cluster in sorted(data['cluster'].unique()):\n",
    "        cluster_data = data[data['cluster'] == cluster].drop(columns='cluster')\n",
    "        cluster_data = cluster_data.loc[:, (cluster_data != 0).any(axis=0)]\n",
    "        sorted_columns = cluster_data.sum(axis=0).sort_values(ascending=False).index\n",
    "        cluster_data = cluster_data[sorted_columns]\n",
    "\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        sns.heatmap(cluster_data, cmap='inferno', cbar=False, square=True)\n",
    "        plt.xlabel('主题')\n",
    "        plt.ylabel('省级行政区')\n",
    "        plt.title(f'聚类 {cluster} 内的主题词热图')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.show()\n",
    "\n",
    "def find_optimal_clusters(data, method='ward', metric='euclidean', max_clusters=10):\n",
    "    data = data.copy()\n",
    "    Z = linkage(data, method=method, metric=metric)\n",
    "    silhouette_scores = []\n",
    "    for num_clusters in range(2, max_clusters + 1):\n",
    "        clusters = fcluster(Z, t=num_clusters, criterion='maxclust')\n",
    "        score = silhouette_score(data, clusters, metric=metric)\n",
    "        silhouette_scores.append(score)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(2, max_clusters + 1), silhouette_scores, marker='o')\n",
    "    plt.xlabel('聚类数')\n",
    "    plt.ylabel('轮廓系数')\n",
    "    plt.title('不同聚类数的轮廓系数')\n",
    "    plt.show()\n",
    "\n",
    "plot_hierarchical_clusters(data=heatmap_df.copy(), method='ward', metric='euclidean', num_clusters=4)"
   ],
   "id": "10190d5f1b9ec5be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "def dbscan_grid_search(data, eps_range, min_samples_range):\n",
    "    def score_func(params):\n",
    "        clusters = DBSCAN(eps=params[0], min_samples=params[1]).fit_predict(data)\n",
    "        if len(set(clusters)) > 1:\n",
    "            score = silhouette_score(data, clusters)\n",
    "            return score, params\n",
    "        else:\n",
    "            return -1, params\n",
    "\n",
    "    _, best_params = max(map(score_func, itertools.product(eps_range, min_samples_range)),\n",
    "                         key=lambda x: x[0])\n",
    "    return best_params\n",
    "\n",
    "eps_range = np.arange(0.5, 5.5, 0.5)\n",
    "min_samples_range = np.arange(2, 6, 1)\n",
    "best_eps, best_min_samples = dbscan_grid_search(heatmap_df, eps_range, min_samples_range)\n",
    "print(f'最佳参数: eps={best_eps}, min_samples={best_min_samples}')\n",
    "\n",
    "\n",
    "def plot_dbscan_clusters(data, cluster_data):\n",
    "    def display_noise_data(noise_df):\n",
    "        def sorted_by_pinyin(sequence):\n",
    "            return sorted(sequence, key=locale.strxfrm)\n",
    "        \n",
    "        def col_names_to_text(row, sep=', '):\n",
    "            return sep.join(sorted_by_pinyin(row.index))\n",
    "        \n",
    "        if not noise_df.empty:\n",
    "            noise_df = noise_df.loc[:, (noise_df != 0).any(axis=0)].copy()\n",
    "            noise_df = pd.DataFrame(noise_df.apply(lambda row: col_names_to_text(row[row != 0]), axis=1),\n",
    "                                    index=noise_df.index, columns=['themes'])\n",
    "            noise_df.to_csv(rf'output/clusters/noises.csv',\n",
    "                            encoding='utf-8-sig', quoting=csv.QUOTE_ALL)\n",
    "\n",
    "    def plot_dbscan_cluster(cluster):\n",
    "        def sorted_by_sum_and_pinyin(df):\n",
    "            sums = df.sum(axis=0)\n",
    "            return df[sorted(df.columns, key=lambda col: (-sums[col], locale.strxfrm(col)))]\n",
    "        \n",
    "        cluster_heatmap_data = data[get_cluster_mask(cluster)]\n",
    "        cluster_heatmap_data = cluster_heatmap_data.loc[:, (cluster_heatmap_data != 0).any(axis=0)]\n",
    "\n",
    "        plt.figure(figsize=(15, 9), dpi=160)\n",
    "        sns.heatmap(sorted_by_sum_and_pinyin(cluster_heatmap_data),\n",
    "                    cmap='magma', square=True, cbar=False)\n",
    "        plt.xlabel('主题')\n",
    "        plt.ylabel('省级行政区')\n",
    "        plt.title(f'聚类 {cluster} 内的主题词热图')\n",
    "        plt.xticks(rotation=30, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(rf'output/clusters/cluster_{cluster}_heatmap.png')\n",
    "        plt.show()\n",
    "\n",
    "    def get_cluster_mask(cluster):\n",
    "        return cluster_data['cluster'] == cluster\n",
    "    \n",
    "    display_noise_data(data[get_cluster_mask(-1)])\n",
    "    \n",
    "    data = data[~get_cluster_mask(-1)]\n",
    "    cluster_data = cluster_data[~get_cluster_mask(-1)]\n",
    "\n",
    "    for cluster in sorted(cluster_data['cluster'].unique()):\n",
    "        plot_dbscan_cluster(cluster)\n",
    "\n",
    "\n",
    "clusters = DBSCAN(eps=best_eps, min_samples=best_min_samples).fit_predict(heatmap_df)\n",
    "cluster_df = pd.DataFrame(clusters, index=heatmap_df.index, columns=['cluster'])\n",
    "plot_dbscan_clusters(heatmap_df, cluster_df)"
   ],
   "id": "8454dd061443db91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "China = gpd.read_file('中华人民共和国.geojson')\n",
    "China = pd.merge(China, cluster_df, left_on='name', right_on='PLAD', how='left')"
   ],
   "id": "a952461da19e9604",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "_, ax = plt.subplots(figsize=(15, 15), dpi=160)\n",
    "\n",
    "China.boundary.plot(ax=ax, linewidth=1)\n",
    "China.plot(column='cluster', ax=ax, legend=True, cmap='Dark2', categorical=True, \n",
    "           legend_kwds={'labels': ['噪声点', '聚类0', '聚类1', '聚类2', '未知']},\n",
    "           missing_kwds={'color': 'lightgray'})\n",
    "\n",
    "plt.title('中国各省级行政区主题词汇表聚类图')\n",
    "plt.tight_layout()\n",
    "plt.savefig(rf'output/clusters/cluster_cnmap.png')\n",
    "plt.show()"
   ],
   "id": "3abe1f3466789a53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5ed81c0e8bc93327",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CNDataAudit)",
   "language": "python",
   "name": "cndataaudit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
