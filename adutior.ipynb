{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-04T23:47:28.289331Z",
     "start_time": "2024-05-04T23:47:28.239460Z"
    }
   },
   "source": [
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import csv\n",
    "import os\n",
    "from enum import Enum, auto\n",
    "\n",
    "class DataQualityIssue(Enum):\n",
    "    STRUCTURAL_INTEGRITY_ISSUES = auto()\n",
    "    UN_TIMELY = auto()\n",
    "    EMPTY = auto()\n",
    "    INCONSISTENT = auto()\n",
    "    DUPLICATE = auto()\n",
    "    FORMAT_ERROR = auto()\n",
    "\n",
    "\n",
    "class Timeliness(Enum):\n",
    "    TIMELY = '及时'\n",
    "    UNTIMELY = '不及时'\n",
    "    UNDETERMINED = '无法判断'\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.value\n",
    "\n",
    "matplotlib.rcParams['font.sans-serif'] = ['SimHei']\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "dataset_dir = r'D:\\Data\\workspace\\python\\projects\\CNDataAuditOutput\\sichuan\\datasets'\n",
    "empties_dir = r'D:\\Data\\workspace\\python\\projects\\CNDataAuditOutput\\sichuan\\empty_datasets'\n",
    "integrity_issues_dir = r'D:\\Data\\workspace\\python\\projects\\CNDataAuditOutput\\sichuan\\structural_issues_datasets'\n",
    "catalog_path = r'D:\\Data\\workspace\\python\\projects\\CNDataAuditOutput\\sichuan\\dataset_catalog.json'\n",
    "catalog_dtype = {'name': str, 'id': str, 'URL': str, 'owner': str, 'category': 'category',\n",
    "                 'published': 'datetime64[ns]', 'updated': 'datetime64[ns]',\n",
    "                 'frequency': 'category', 'sample_data': object}\n",
    "null_values = ['无', '未知', '/', '-', '', ' ', '&nbsp;', 'null', 'NULL', 'N/A', ]\n",
    "\n",
    "\n",
    "def read_csv(dataset_name, directory=dataset_dir):\n",
    "    return pd.read_csv(dataset_file_path(dataset_name, directory),\n",
    "                       encoding='gbk', na_values=null_values,\n",
    "                       encoding_errors='ignore')\n",
    "\n",
    "def dataset_files(directory=dataset_dir):\n",
    "    return (f for f in os.listdir(directory) if f.endswith('.csv'))\n",
    "\n",
    "def dataset_file_path(filename: str, directory=dataset_dir):\n",
    "    if not filename.endswith('.csv'):\n",
    "        filename += '.csv'\n",
    "    return os.path.join(directory, filename)\n",
    "\n",
    "def dataset_completeness(dataset_df):\n",
    "    return ((dataset_df.size - dataset_df.isna().sum().sum()) / dataset_df.size) * 100\n",
    "\n",
    "def exists(dataset_name, directory=dataset_dir):\n",
    "    return os.path.exists(dataset_file_path(dataset_name, directory))\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T23:47:30.011563Z",
     "start_time": "2024-05-04T23:47:29.956709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "catalog_df = pd.read_json(catalog_path, dtype=catalog_dtype)\n",
    "print(catalog_df.info())\n",
    "print(catalog_df['category'].value_counts())\n",
    "print(catalog_df['frequency'].value_counts())"
   ],
   "id": "8a0cce08c70abe1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3777 entries, 0 to 3776\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   name         3777 non-null   object        \n",
      " 1   id           3777 non-null   object        \n",
      " 2   URL          3777 non-null   object        \n",
      " 3   owner        3777 non-null   object        \n",
      " 4   category     3777 non-null   category      \n",
      " 5   published    3777 non-null   datetime64[ns]\n",
      " 6   updated      3777 non-null   datetime64[ns]\n",
      " 7   frequency    3777 non-null   category      \n",
      " 8   sample_data  3776 non-null   object        \n",
      "dtypes: category(2), datetime64[ns](2), object(5)\n",
      "memory usage: 215.1+ KB\n",
      "None\n",
      "category\n",
      "社保就业         946\n",
      "医疗卫生         463\n",
      "市场监管         360\n",
      "生活服务         355\n",
      "教育文化         234\n",
      "生态环境         219\n",
      "工业农业         189\n",
      "公共安全         140\n",
      "信用服务         132\n",
      "财税金融         124\n",
      "交通运输         110\n",
      "城建住房         107\n",
      "能源资源          80\n",
      "社会救助          78\n",
      "机构团体          53\n",
      "商贸流通          48\n",
      "气象服务          38\n",
      "科技创新          31\n",
      "法律服务          24\n",
      "地理空间          23\n",
      "安全生产          20\n",
      "工业农业 财税金融      1\n",
      "机构团体 教育文化      1\n",
      "能源资源 交通运输      1\n",
      "Name: count, dtype: int64\n",
      "frequency\n",
      "不定期    1818\n",
      "每年      981\n",
      "每天      330\n",
      "实时      246\n",
      "每月      213\n",
      "每半年     117\n",
      "每季度      54\n",
      "每周       18\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compare_datasets(catalog_df):\n",
    "    dataset_names_from_files = [os.path.splitext(f)[0] for f in dataset_files()]\n",
    "    dataset_names_from_catalog = catalog_df['name'].tolist()\n",
    "    datasets_not_in_catalog = set(dataset_names_from_files) - set(dataset_names_from_catalog)\n",
    "    datasets_in_catalog_not_found = set(dataset_names_from_catalog) - set(dataset_names_from_files)\n",
    "    return datasets_not_in_catalog, datasets_in_catalog_not_found\n",
    "\n",
    "datasets_not_in_catalog, datasets_in_catalog_not_found = compare_datasets(catalog_df)\n",
    "print(\"Datasets not in catalog:\", len(datasets_not_in_catalog))\n",
    "print(\"Datasets in catalog but not found in files:\", len(datasets_in_catalog_not_found))\n",
    "\n",
    "def remove_files(names):\n",
    "    count = 0\n",
    "    for dataset_name in names:\n",
    "      if exists(dataset_name):\n",
    "          os.remove(dataset_file_path(dataset_name))\n",
    "          count += 1\n",
    "      else:\n",
    "          print(f\"File not found: {dataset_file_path(dataset_name)}\")\n",
    "    print(count)\n",
    "\n",
    "def remove_records(names):\n",
    "    filtered_df = catalog_df[~catalog_df['name'].isin(names)]\n",
    "    str_filtered_df = filtered_df.astype(str)\n",
    "    # last column as type dict\n",
    "    str_filtered_df['sample_data'] = filtered_df['sample_data']\n",
    "    print(len(str_filtered_df))\n",
    "    return str_filtered_df\n",
    "\n",
    "# remove_files(datasets_not_in_catalog)\n",
    "# filtered = remove_records(set(duplicates['name'].tolist()))\n",
    "# filtered.to_json('updated_catalog.json', orient='records', force_ascii=False)"
   ],
   "id": "dbc5f03a4dc04738"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def remove_duplicated_datasets_by_name():\n",
    "    duplicates = catalog_df[catalog_df.duplicated('name', keep=False)]\n",
    "    print(\"Duplicate records based on 'name':\")\n",
    "    print(len(duplicates), duplicates['name'].sort_values())\n",
    "    remove_files(set(duplicates['name'].tolist()))\n",
    "\n",
    "remove_duplicated_datasets_by_name()"
   ],
   "id": "195bc604fd28d640"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def move_empty_datasets():\n",
    "    os.makedirs(empties_dir, exist_ok=True)\n",
    "    is_empty_sample = catalog_df['sample_data'].apply(lambda x: x == {'null': 'null'})\n",
    "    \n",
    "    for index, row in catalog_df[is_empty_sample].iterrows():\n",
    "        file_name = f\"{row['name']}.csv\"\n",
    "        source_path = dataset_file_path(file_name)\n",
    "        destination_path = dataset_file_path(file_name)\n",
    "        shutil.move(source_path, destination_path)\n",
    "        print(f\"Moved '{file_name}' to {empties_dir}\")"
   ],
   "id": "8e6a7dc036a79e40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T07:22:54.100982Z",
     "start_time": "2024-05-04T07:22:49.981694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_csv_structural_integrity():\n",
    "    integrity_issues = {}\n",
    "    for file in dataset_files():\n",
    "        file_name = os.path.splitext(file)[0]\n",
    "        integrity_issues[file_name] = detect_csv_structural_issues(dataset_file_path(file_name))\n",
    "    return pd.DataFrame(list(integrity_issues.items()), columns=['文件名', '首个异常行标'])\n",
    "\n",
    "def detect_csv_structural_issues(file_path):\n",
    "    with open(file_path, encoding='gbk', errors='ignore') as file:\n",
    "        reader = csv.reader(file)\n",
    "        expected_columns = len(next(reader))\n",
    "        for row_index, row in enumerate(reader, 1):\n",
    "            if len(row) != expected_columns:\n",
    "                return row_index\n",
    "    return -1\n",
    "\n",
    "def move_structural_issues(destination_dir):\n",
    "    os.makedirs(destination_dir, exist_ok=True)\n",
    "    for file in dataset_files():\n",
    "        if detect_csv_structural_issues(dataset_file_path(file)) != -1:\n",
    "            shutil.move(dataset_file_path(file), dataset_file_path(file, directory=destination_dir))\n",
    "            print(f\"Moved '{dataset_file_path(file)}' to '{dataset_file_path(file, directory=destination_dir)}'\")\n",
    "\n",
    "\n",
    "integrity_df = evaluate_csv_structural_integrity()\n",
    "# move_structural_issues(anomalies_dir)\n",
    "print(integrity_df['首个异常行标'].value_counts())\n",
    "integrity_df[integrity_df['首个异常行标'] != -1]"
   ],
   "id": "ac8398002229f24a",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T23:50:32.796408Z",
     "start_time": "2024-05-04T23:50:30.534163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def evaluate_completeness(catalog_df):\n",
    "    def completeness(dataset_name):\n",
    "        return dataset_completeness(read_csv(dataset_name)) if exists(dataset_name) else None\n",
    "\n",
    "    completeness_scores = Parallel(n_jobs=-1)(delayed(completeness)(name)\n",
    "                                              for name in catalog_df['name'])\n",
    "    catalog_df['completeness'] = completeness_scores\n",
    "\n",
    "\n",
    "# catalog_df['completeness'].hist()\n",
    "evaluate_completeness(catalog_df)\n",
    "catalog_df['completeness'].value_counts(dropna=False)"
   ],
   "id": "806caf53f28b205a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "completeness\n",
       "100.000000    1385\n",
       "NaN            805\n",
       "83.333333       50\n",
       "80.000000       39\n",
       "85.714286       33\n",
       "              ... \n",
       "53.703704        1\n",
       "70.897436        1\n",
       "90.277778        1\n",
       "99.914286        1\n",
       "99.988235        1\n",
       "Name: count, Length: 1092, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T23:50:57.193729Z",
     "start_time": "2024-05-04T23:50:57.132416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "def evaluate_timeliness(catalog_df):\n",
    "    def timeliness(dataset, now, days_map):\n",
    "        days = days_map.get(dataset['frequency'], None)\n",
    "        if days is None:\n",
    "            return Timeliness.UNDETERMINED\n",
    "        return (Timeliness.TIMELY\n",
    "                if now - dataset['updated'] <= timedelta(days=days)\n",
    "                else Timeliness.UNTIMELY)\n",
    "\n",
    "    downloaded = pd.Timestamp('2024-04-30 20:00:00')\n",
    "    frequency_to_days = {'实时': 0, '每天': 1, '每周': 7, '每月': 30,\n",
    "                         '每季度': 90, '每半年': 183, '每年': 365}\n",
    "    catalog_df['timeliness'] = catalog_df.apply(timeliness, axis=1,\n",
    "                                                args=(downloaded, frequency_to_days))\n",
    "\n",
    "def timeliness_freq_distribution():\n",
    "    timely_df = catalog_df[catalog_df['timeliness'] == Timeliness.TIMELY]\n",
    "    untimely_df = catalog_df[catalog_df['timeliness'] == Timeliness.UNTIMELY]\n",
    "    return timely_df['frequency'].value_counts(), untimely_df['frequency'].value_counts()\n",
    "\n",
    "\n",
    "def print_timeliness_freq_distribution():\n",
    "    timely_freq_counts, untimely_freq_counts = timeliness_freq_distribution()\n",
    "    print('Frequency distribution for timely updates:')\n",
    "    print(timely_freq_counts)\n",
    "    print('Frequency distribution for untimely updates:')\n",
    "    print(untimely_freq_counts)\n",
    "\n",
    "\n",
    "def visualize_timeliness_distribution(save_path=None):\n",
    "    def autopct_format(values):\n",
    "        def my_format(pct):\n",
    "            val = int(round(pct * sum(values) / 100.0))\n",
    "            return '{v:d} ({p:.2f}%)'.format(v=val, p=pct) if pct > 0 else ''\n",
    "        return my_format\n",
    "    \n",
    "    timely_freq_counts, untimely_freq_counts = timeliness_freq_distribution()\n",
    "    _timely_freq_counts = timely_freq_counts[timely_freq_counts > 0]\n",
    "    _untimely_freq_counts = untimely_freq_counts[untimely_freq_counts > 0]\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 9))\n",
    "    axes[0].pie(_timely_freq_counts, labels=_timely_freq_counts.index,\n",
    "                autopct=autopct_format(_timely_freq_counts), startangle=140)\n",
    "    axes[1].pie(_untimely_freq_counts, labels=_untimely_freq_counts.index,\n",
    "                autopct=autopct_format(_untimely_freq_counts), startangle=140)\n",
    "    axes[0].set_title('及时更新的数据集更新频率分布')\n",
    "    axes[1].set_title('未及时更新的数据集更新频率分布')\n",
    "    fig.text(0.5, 0.01, '评估时间：2024-04-30 20:00:00', ha='center', va='bottom', fontsize=10)\n",
    "    fig.tight_layout()\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "evaluate_timeliness(catalog_df)\n",
    "print_timeliness_freq_distribution()\n",
    "# visualize_timeliness_distribution(save_path='timeliness_distribution.png')\n",
    "catalog_df['timeliness'].value_counts(dropna=False)"
   ],
   "id": "a4797e355ca7ce02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency distribution for timely updates:\n",
      "frequency\n",
      "每年     980\n",
      "每半年     15\n",
      "每月       1\n",
      "不定期      0\n",
      "实时       0\n",
      "每周       0\n",
      "每天       0\n",
      "每季度      0\n",
      "Name: count, dtype: int64\n",
      "Frequency distribution for untimely updates:\n",
      "frequency\n",
      "每天     330\n",
      "实时     246\n",
      "每月     212\n",
      "每半年    102\n",
      "每季度     54\n",
      "每周      18\n",
      "每年       1\n",
      "不定期      0\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "timeliness\n",
       "无法判断    1818\n",
       "及时       996\n",
       "不及时      963\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T12:05:27.483711Z",
     "start_time": "2024-05-04T12:05:16.162005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_data_quality(catalog_df):\n",
    "    evaluate_completeness(catalog_df)\n",
    "    evaluate_timeliness(catalog_df)\n",
    "\n",
    "evaluate_data_quality(catalog_df)"
   ],
   "id": "1d8a81df510c577d",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T12:35:53.483770Z",
     "start_time": "2024-05-04T12:35:53.407972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def view(catalog_df):\n",
    "    return catalog_df[['name', 'owner', 'category', 'completeness', 'timeliness', ]]\n",
    "\n",
    "catalog_view = view(catalog_df)\n",
    "catalog_view.sample(5)"
   ],
   "id": "aa9d079fa3566d17",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                 name       owner category timeliness  \\\n",
       "2374                       食盐定点生产企业证书    省经济和信息化厅     市场监管         及时   \n",
       "1297                 资阳市_经信局_工业园区营业收入  资阳市经济和信息化局     工业农业       无法判断   \n",
       "999                   四川省大气环境重点排污单位信息       生态环境厅     生态环境       无法判断   \n",
       "2842  巴中市_南江县人民政府办公室_公共财政支出预算经济科目款明细表  南江县人民政府办公室     生活服务       无法判断   \n",
       "778              南充市_嘉陵区_嘉陵区图书馆借书流通信息         南充市     生活服务         及时   \n",
       "\n",
       "      completeness  \n",
       "2374         100.0  \n",
       "1297         100.0  \n",
       "999           88.0  \n",
       "2842         100.0  \n",
       "778            NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>owner</th>\n",
       "      <th>category</th>\n",
       "      <th>timeliness</th>\n",
       "      <th>completeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "      <td>食盐定点生产企业证书</td>\n",
       "      <td>省经济和信息化厅</td>\n",
       "      <td>市场监管</td>\n",
       "      <td>及时</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>资阳市_经信局_工业园区营业收入</td>\n",
       "      <td>资阳市经济和信息化局</td>\n",
       "      <td>工业农业</td>\n",
       "      <td>无法判断</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>四川省大气环境重点排污单位信息</td>\n",
       "      <td>生态环境厅</td>\n",
       "      <td>生态环境</td>\n",
       "      <td>无法判断</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2842</th>\n",
       "      <td>巴中市_南江县人民政府办公室_公共财政支出预算经济科目款明细表</td>\n",
       "      <td>南江县人民政府办公室</td>\n",
       "      <td>生活服务</td>\n",
       "      <td>无法判断</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>南充市_嘉陵区_嘉陵区图书馆借书流通信息</td>\n",
       "      <td>南充市</td>\n",
       "      <td>生活服务</td>\n",
       "      <td>及时</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d08d3a00ab31a818"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
